---
📅 **날짜**: 2024년 10월 18일 (금)
👤 **작성자**: 강철원 (연구책임자) | **승인**: 강혜림 (대표)
📊 **진행 단계**: 1단계 - 기초연구 및 설계
🎯 **주요 작업**: Wav2Lip 조사 및 주간 정리
---

# AI 기반 다국어 음성 합성 및 실시간 립싱크 더빙 시스템 개발일지

## 📋 오늘의 작업 내용

### 1. Wav2Lip 분석

- **특징**: 임의의 오디오와 비디오를 입력받아 입모양을 동기화.
- **성능**: 현재 공개된 모델 중 가장 안정적인 성능. GAN 기반.
- **제약**: 상업적 이용 시 라이선스 확인 필요 (LRS2 데이터셋 이슈). 연구용으로 우선 진행.

### 2. 주간 정리

- **성과**: 개발 환경 구축 완료, 핵심 AI 모델(Whisper, VALL-E X, RVC, Wav2Lip) 선정 및 분석 완료.
- **방향성**: "정확도"와 "품질"을 최우선으로 하는 파이프라인 설계 확정.

## 🔧 기술적 진행사항

### Model Selection

- **STT**: Faster-Whisper (Large-v3)
- **TTS**: VALL-E X
- **VC**: RVC v2
- **LipSync**: Wav2Lip (+ GAN)

## 📊 진행 상황

| 항목 | 계획 | 실제 | 상태 |
|------|------|------|------|
| Wav2Lip 분석 | 완료 | 완료 | ✅ |
| 주간 보고 | 완료 | 완료 | ✅ |

## 🚧 이슈 사항 및 해결 방안

- **라이선스**: Wav2Lip의 상업적 이용 제한. -> 대체 모델(SadTalker 등)도 지속 모니터링하되, 현재는 Wav2Lip으로 프로토타입 개발.

## 📝 다음 주 계획 (10.21 ~ 10.25)

1. 오디오 추출 모듈(FFmpeg) 구현
2. STT 모듈 프로토타이핑

---

## 📚 참고 자료

- [1] "Wav2Lip GitHub". [Link](https://github.com/Rudrabha/Wav2Lip)

<details>
<summary>IRIS 붙여넣기용 HTML 코드</summary>

```html
<h3>1. Wav2Lip 분석</h3>
<ul>
<li><strong>특징</strong>: 임의의 오디오와 비디오를 입력받아 입모양을 동기화.</li>
<li><strong>성능</strong>: 현재 공개된 모델 중 가장 안정적인 성능. GAN 기반.</li>
<li><strong>제약</strong>: 상업적 이용 시 라이선스 확인 필요 (LRS2 데이터셋 이슈). 연구용으로 우선 진행.</li>
</ul>
<h3>2. 주간 정리</h3>
<ul>
<li><strong>성과</strong>: 개발 환경 구축 완료, 핵심 AI 모델(Whisper, VALL-E X, RVC, Wav2Lip) 선정 및 분석 완료.</li>
<li><strong>방향성</strong>: "정확도"와 "품질"을 최우선으로 하는 파이프라인 설계 확정.</li>
</ul>
```

</details>
