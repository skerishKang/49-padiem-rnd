---
📅 **날짜**: 2025년 6월 11일 (수)
👤 **작성자**: 강철원 (연구책임자) | **승인**: 강혜림 (대표)
📊 **진행 단계**: 3단계 - 시스템 통합 및 고도화
🎯 **주요 작업**: Wav2Lip 연동 및 최종 결과 생성
---

# AI 기반 다국어 음성 합성 및 실시간 립싱크 더빙 시스템 개발일지

## 📋 오늘의 작업 내용

### 1. Wav2Lip 연동

- `backend/routers/lipsync.py`: 원본 비디오와 더빙된 오디오(RVC 결과)를 합성.
- **기능**: 오디오의 발음에 맞춰 비디오 속 인물의 입모양을 변형.
- **모델**: `wav2lip_gan.pth` 사용 (화질 저하 최소화).

### 2. 결과물 병합

- `ffmpeg`를 사용하여 립싱크된 비디오에 최종 오디오 트랙을 입혀 `mp4` 파일 생성.
- Streamlit에서 최종 결과 영상을 재생하고 다운로드할 수 있는 버튼 제공.

## 🔧 기술적 진행사항

### Lip-Sync Process

- Face Detection (S3FD) -> Face Cropping -> Wav2Lip Inference -> Face Restoration (GFPGAN 옵션).

## 📊 진행 상황

| 항목 | 계획 | 실제 | 상태 |
|------|------|------|------|
| Wav2Lip API | 완료 | 완료 | ✅ |
| 결과 병합 | 완료 | 완료 | ✅ |

## 🚧 이슈 사항 및 해결 방안

- **얼굴 인식 실패**: 측면 얼굴이나 가려진 얼굴 인식률 저하. -> `pads` 파라미터 조절하여 인식 영역 확장 시도.

## 📝 내일 계획

1. 통합 테스트 (End-to-End)
2. 버그 수정 및 안정화

---

## 📚 참고 자료

- [1] "Wav2Lip Repository". [Link](https://github.com/Rudrabha/Wav2Lip)

<details>
<summary>IRIS 붙여넣기용 HTML 코드</summary>

```html
<h3>1. Wav2Lip 연동</h3>
<ul>
<li><code>backend/routers/lipsync.py</code>: 원본 비디오와 더빙된 오디오(RVC 결과)를 합성.</li>
<li><strong>기능</strong>: 오디오의 발음에 맞춰 비디오 속 인물의 입모양을 변형.</li>
<li><strong>모델</strong>: <code>wav2lip_gan.pth</code> 사용 (화질 저하 최소화).</li>
</ul>
<h3>2. 결과물 병합</h3>
<ul>
<li><code>ffmpeg</code>를 사용하여 립싱크된 비디오에 최종 오디오 트랙을 입혀 <code>mp4</code> 파일 생성.</li>
<li>Streamlit에서 최종 결과 영상을 재생하고 다운로드할 수 있는 버튼 제공.</li>
</ul>
```

</details>
