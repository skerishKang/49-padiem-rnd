---
📅 **날짜**: 2025년 8월 20일 (수)
👤 **작성자**: 강철원 (연구책임자) | **승인**: 강혜림 (대표)
📊 **진행 단계**: 4단계 - 사업화 준비 및 안정화
🎯 **주요 작업**: 화자 분리 프로토타이핑
---

# AI 기반 다국어 음성 합성 및 실시간 립싱크 더빙 시스템 개발일지

## 📋 오늘의 작업 내용

### 1. Pyannote 연동

- `backend/routers/audio.py`에 화자 분리 로직 추가 (실험적 기능).
- **결과**: 오디오 파일에서 "누가 언제 말했는지" 타임스탬프(RTTM) 추출.

### 2. UI 테스트

- Streamlit에 화자별 구간을 시각화(Timeline)하여 보여주는 위젯 추가.
- 사용자가 화자 A, B, C에 대해 각각 다른 TTS 목소리를 할당할 수 있도록 UI 구성.

## 🔧 기술적 진행사항

### Speaker Diarization

```python
pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization")
diarization = pipeline("audio.wav")
```

- Hugging Face 토큰 필요.

## 📊 진행 상황

| 항목 | 계획 | 실제 | 상태 |
|------|------|------|------|
| 모델 연동 | 완료 | 완료 | ✅ |
| UI 프로토타입 | 완료 | 완료 | ✅ |

## 🚧 이슈 사항 및 해결 방안

- **속도**: 1분 오디오 처리에 30초 소요. -> 실시간성 부족. 백그라운드 작업으로 전환.

## 📝 내일 계획

1. 화자별 TTS 생성 로직 구현
2. 통합 테스트

---

## 📚 참고 자료

- [1] "Hugging Face Pyannote". [Link](https://huggingface.co/pyannote/speaker-diarization)

<details>
<summary>IRIS 붙여넣기용 HTML 코드</summary>

```html
<h3>1. Pyannote 연동</h3>
<ul>
<li><code>backend/routers/audio.py</code>에 화자 분리 로직 추가 (실험적 기능).</li>
<li><strong>결과</strong>: 오디오 파일에서 "누가 언제 말했는지" 타임스탬프(RTTM) 추출.</li>
</ul>
<h3>2. UI 테스트</h3>
<ul>
<li>Streamlit에 화자별 구간을 시각화(Timeline)하여 보여주는 위젯 추가.</li>
<li>사용자가 화자 A, B, C에 대해 각각 다른 TTS 목소리를 할당할 수 있도록 UI 구성.</li>
</ul>
```

</details>
