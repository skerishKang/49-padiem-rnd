# 연구노트 (책임자 관점)

- **날짜**: 2024-10-16
- **작성자**: 강혜림
- **역할**: 책임연구원
- **진행 단계**: 1단계 기초연구·설계
- **아젠다**: GPU 최적화(혼합정밀도, 체크포인팅), 추론 지연시간/메모리/throughput 튜닝 전략 확정

---

## 1. 연구 배경·목적 정리 (책임 관점)

- 10/11에 합의한 모델 파라미터 구성을 실제 GPU 환경(A100 80GB x2)에서 검증하고,
  - 추론 지연시간,
  - GPU 메모리 사용량,
  - throughput(초당 처리 clip 수)
  사이의 균형점을 찾는 것이 목적.
- IRIS 연구계획서에서 제시한 목표(추론 지연시간 500ms 이하 등)를 실제 인프라 수준에서 만족시킬 수 있는지 확인하는 단계.

---

## 2. 오늘 진행 내용 (세부)

### 2.1 실험 환경 세팅
- NVIDIA A100 80GB x2, CUDA 12.3, PyTorch 2.2, TensorRT 9.1 조합으로 벤치마크 환경 구성.
- 동일 환경을 재현할 수 있도록 컨테이너 이미지·드라이버 버전까지 기록.

### 2.2 Mixed Precision & Gradient Checkpointing 적용
- VALL-E X 학습·추론 경로에 fp16 mixed precision 적용.
- gradient checkpointing을 도입해 메모리 사용량을 52GB → 34GB로 감소.
- 책임자 관점에서, 이 설정은 향후 IRIS 제출 및 시연 환경(동일 또는 유사 GPU)에서도 유지 가능한지 검토 필요.

### 2.3 파이프라인 병렬화
- RVC → VALL-E X → FastPitch → Wav2Lip 순서를 일부 병렬화하여 GPU 유휴 시간을 줄이는 파이프라인 패턴을 설계.
- latency hiding 기법을 활용해, 싱글 스트림 기준 추론 지연시간을 추가로 단축할 수 있는 여지를 확인.

### 2.4 TensorRT 엔진 빌드
- FastPitch, Wav2Lip 추론 그래프에 대해 TensorRT INT8 calibration을 수행.
- 초기 결과로 약 1.4배 추론 속도 향상 가능성을 확인.

### 2.5 자동 성능 리포트 도구
- `benchmark_runner.py`를 작성해, clip 길이(5/10/30초)별로 지연시간·메모리·SM 사용률을 CSV로 내보내도록 구성.

---

## 3. 책임자 관점 의사결정·리스크

- **결정 1: 공식 벤치마크 기준 환경**
  - A100 80GB를 기준 환경으로 삼고, IRIS 보고서에는 이 환경 기준 수치를 명시.
  - 향후 다른 환경(V100, 4090 등)은 별도 부록이나 참고자료로 기록.

- **결정 2: Mixed Precision 기본값 채택**
  - 품질 열화가 허용 가능한 수준이라는 가정을 두고, mixed precision을 기본값으로 채택.
  - 품질 평가는 10월 말/11월 초 벤치마크에서 다시 확인.

- **리스크 1: Long clip(30초 이상) 처리시 메모리 피크**
  - 30초 이상 clip에서 여전히 메모리 피크가 발생.
  - → **대응**: chunk 단위 inference 로직을 10/21까지 구현해 이 문제를 구조적으로 해소.

- **리스크 2: 복잡한 튜닝 조합 관리**
  - mixed precision, checkpointing, TensorRT, 파이프라인 병렬화 등 튜닝 축이 많아 조합 관리가 어려움.
  - → **대응**: `benchmark_runner.py` 기준으로 실험 설정을 명시적으로 남기고, IRIS 보고서에는 대표 조합만 수치로 제시.

---

## 4. 지표·산출물 정리

- **성능 지표(초기)**
  - 평균 추론 지연시간: 5초 clip 기준 342ms.
  - throughput: 2.7 clips/s.
  - GPU 메모리 사용량: 약 38GB.
- **도구**
  - `benchmark_runner.py`: 성능 리포트 자동화.

---

## 5. 다음 액션 (책임 관점 To-do)

1. **10/17 데모 준비와 연계**
   - 오늘 얻은 성능 설정을 10/17 데모 시나리오에 반영해, 실제 시연에서도 유사한 지표를 보여줄 수 있도록 할 것.

2. **10/21 chunked inference 구현**
   - 30초 이상 clip 처리 안정화를 위해 chunk 기반 inference를 도입하고, 오늘 성능 수치와 비교해보고 IRIS 보고서에 반영.

---

## 6. 참고 문서·링크

- NVIDIA TensorRT Best Practices, 2024.
- OpenAI Mixed Precision Training, 2023.
- IRIS 연구계획서 PART2(GPU 구성 안내).

> 메모: 이 노트는 2024-10-16 원본 연구노트의 GPU 최적화 실험 내용을 책임자 입장에서 정리한 것이다. 이후 chunked inference 설계(10/21) 및 10월 말 KPI 요약에 포함될 주요 수치를 제공한다.