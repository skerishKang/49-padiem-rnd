# 연구노트 (책임자 관점)

- **날짜**: 2024-11-07
- **작성자**: 강혜림
- **역할**: 책임연구원
- **진행 단계**: 2단계 서비스·운영 통합 검증
- **अ젠다**: AI 파이프라인 2차 튜닝(멀티모달 스케줄러, LoRA, 리소스 최적화)

---

## 1. 연구 배경·목적 (책임 관점)

- 1차 튜닝 이후에도 STT→LLM→TTS 전체 파이프라인에 여전히 병목 구간이 존재.
- 목표는
  - 멀티모달(음성·텍스트·영상) 처리에서 **처리량 10% 이상 개선**,
  - GPU/CPU 자원 활용률을 낮추면서도 MOS(음질 평가 점수)를 유지하는 것.

---

## 2. 오늘 주요 진행 내용

### 2.1 프로파일링
- `nsys`, PyTorch Profiler로 STT 인코더, LLM 응답 생성, TTS 합성 단계별 지연시간 측정.
- STT, TTS 구간에서 각각 28%, 19%의 병목 구간을 식별.

### 2.2 스케줄러 개선
- 우선순위 + 길이(`priority + media length`) 기반 큐잉 전략 도입.
- 5분 이상 세션을 자동 배치 모드로 전환, 짧은 요청은 인터랙티브 모드로 처리.
- CPU 측 자막·메타데이터 처리는 별도 컨테이너로 분리해, GPU 파이프라인과 경쟁하지 않도록 조정.

### 2.3 모델 경량화
- TTS 모델에 LoRA 적용 및 half-precision 변환 시험.
- MOS 평가(내부 리스너 테스트) 결과 품질 저하는 허용 범위(4.35점 수준) 안에 있는 것으로 확인.

### 2.4 실험·검증
- 실제 사용 시나리오 20건에 대해 A/B 테스트 수행.
- 응답 시간·GPU 사용률·MOS 지표를 비교.

---

## 3. 책임자 관점 의사결정·리스크

- **결정**: 프로덕션 환경에서 LoRA+half-precision 조합을 기본값으로 채택하되, 품질 이슈 발생 시 롤백 플랜을 릴리스 노트에 명시.
- **리스크**:
  - LoRA 캐시 미스에 따른 초기 응답 지연 → warm-up 스크립트 도입.
  - 너무 짧은 세션까지 배치 모드로 들어가는 문제 → 배치 임계값을 5분 → 4분으로 조정.

---

## 4. 산출물·지표

- 평균 처리 시간: 8.5분 → 7.3분.
- GPU 사용률: 평균 72% → 61%.
- MOS: 4.35(품질 유지).

---

## 5. 다음 액션 (책임 관점)

1. 11/8: 브라우저/업무망 가이드 및 CDN 로그 정책 보강과 연계해, 파이프라인 변경 사항을 운영 문서에 반영.
2. 11/11: 품질 대시보드에 새로운 성능 지표를 추가해 추적.

---

## 6. 참고 자료

- `docs/pipeline/tuning_round2_notes.md`
- LoRA 논문 및 NVIDIA nsys 프로파일링 가이드.
